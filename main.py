import os
import time
import logging
import requests
from openai import OpenAI
import json
from urllib.parse import urljoin, urlparse
from flask import Flask, request, jsonify
from bs4 import BeautifulSoup
from datetime import datetime
import re

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)

# ‚Äî‚Äî Config ‚Äî‚Äî #
ROOT_URL             = os.getenv("ROOT_URL", "https://docs.cloud.mn/")
DELAY_SEC            = float(os.getenv("DELAY_SEC", "0.5"))
ALLOWED_NETLOC       = urlparse(ROOT_URL).netloc
MAX_CRAWL_PAGES      = int(os.getenv("MAX_CRAWL_PAGES", "50"))
CHATWOOT_API_KEY     = os.getenv("CHATWOOT_API_KEY")
ACCOUNT_ID           = os.getenv("ACCOUNT_ID")
CHATWOOT_BASE_URL    = os.getenv("CHATWOOT_BASE_URL", "https://app.chatwoot.com")
OPENAI_API_KEY       = os.getenv("OPENAI_API_KEY")
AUTO_CRAWL_ON_START  = os.getenv("AUTO_CRAWL_ON_START", "true").lower() == "true"
TEAMS_WEBHOOK_URL    = os.getenv("TEAMS_WEBHOOK_URL")  # Microsoft Teams webhook URL

# Initialize OpenAI client
client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# ‚Äî‚Äî Memory Storage ‚Äî‚Äî #
conversation_memory = {}
crawled_data = []
crawl_status = {"status": "not_started", "message": "Crawling has not started yet"}

# ‚Äî‚Äî Crawl & Scrape ‚Äî‚Äî #
def crawl_and_scrape(start_url: str):
    visited = set()
    to_visit = {start_url}
    results = []

    while to_visit and len(visited) < MAX_CRAWL_PAGES:
        url = to_visit.pop()
        if url in visited:
            continue
        visited.add(url)

        try:
            logging.info(f"[Crawling] {url}")
            resp = requests.get(url, timeout=10)
            resp.raise_for_status()
        except Exception as e:
            logging.warning(f"Failed to fetch {url}: {e}")
            continue

        soup = BeautifulSoup(resp.text, "html.parser")
        title = soup.title.string.strip() if soup.title else url
        body, images = extract_content(soup, url)

        results.append({
            "url": url,
            "title": title,
            "body": body,
            "images": images
        })

        for a in soup.find_all("a", href=True):
            href = a["href"]
            if is_internal_link(href):
                full = normalize_url(url, href)
                if full.startswith(ROOT_URL) and full not in visited:
                    to_visit.add(full)

        time.sleep(DELAY_SEC)

    return results

# ‚Äî‚Äî Startup Functions ‚Äî‚Äî #
def auto_crawl_on_startup():
    """Automatically crawl the site on startup"""
    global crawled_data, crawl_status
    
    if not AUTO_CRAWL_ON_START:
        crawl_status = {"status": "disabled", "message": "Auto-crawl is disabled"}
        logging.info("Auto-crawl is disabled")
        return
    
    try:
        logging.info(f"üöÄ Starting automatic crawl of {ROOT_URL}")
        crawl_status = {"status": "running", "message": f"Crawling {ROOT_URL}..."}
        
        crawled_data = crawl_and_scrape(ROOT_URL)
        
        if crawled_data:
            crawl_status = {
                "status": "completed", 
                "message": f"Successfully crawled {len(crawled_data)} pages",
                "pages_count": len(crawled_data),
                "timestamp": datetime.now().isoformat()
            }
            logging.info(f"‚úÖ Auto-crawl completed: {len(crawled_data)} pages")
        else:
            crawl_status = {"status": "failed", "message": "No pages were crawled"}
            logging.warning("‚ùå Auto-crawl failed: No pages found")
            
    except Exception as e:
        crawl_status = {"status": "error", "message": f"Crawl error: {str(e)}"}
        logging.error(f"‚ùå Auto-crawl error: {e}")

# Start auto-crawl in background when app starts
import threading
if AUTO_CRAWL_ON_START:
    threading.Thread(target=auto_crawl_on_startup, daemon=True).start()

# ‚Äî‚Äî Content Extraction ‚Äî‚Äî #
def extract_content(soup: BeautifulSoup, base_url: str):
    main = soup.find("main") or soup
    texts = []
    images = []

    for tag in main.find_all(["h1", "h2", "h3", "h4", "p", "li", "code"]):
        text = tag.get_text(strip=True)
        if text:
            texts.append(text)

    for img in main.find_all("img"):
        src = img.get("src")
        alt = img.get("alt", "").strip()
        if src:
            full_img_url = urljoin(base_url, src)
            entry = f"[Image] {alt} ‚Äî {full_img_url}" if alt else f"[Image] {full_img_url}"
            texts.append(entry)
            images.append({"url": full_img_url, "alt": alt})

    return "\n\n".join(texts), images

def is_internal_link(href: str) -> bool:
    if not href:
        return False
    parsed = urlparse(href)
    return not parsed.netloc or parsed.netloc == ALLOWED_NETLOC

def normalize_url(base: str, link: str) -> str:
    return urljoin(base, link.split("#")[0])

def scrape_single(url: str):
    resp = requests.get(url, timeout=10)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")
    title = soup.title.string.strip() if soup.title else url
    body, images = extract_content(soup, url)
    return {"url": url, "title": title, "body": body, "images": images}


# ‚Äî‚Äî AI Assistant Functions ‚Äî‚Äî #

# AI Context and Decision System
class AIContext:
    """Unified AI context management for flexible workflow"""
    def __init__(self, conv_id: int, user_message: str):
        self.conv_id = conv_id
        self.user_message = user_message
        self.conversation_history = conversation_memory.get(conv_id, [])
        self.search_results = None
        self.ai_response = None
        self.analysis_result = None
        self.suggested_services = None
        
    def get_full_context(self):
        """Get complete conversation context"""
        user_messages = []
        ai_messages = []
        for msg in self.conversation_history:
            if msg.get("role") == "user":
                user_messages.append(msg.get("content", ""))
            elif msg.get("role") == "assistant":
                ai_messages.append(msg.get("content", ""))
        
        # Add current message
        if self.user_message not in user_messages:
            user_messages.append(self.user_message)
            
        return {
            "user_messages": user_messages,
            "ai_messages": ai_messages,
            "full_conversation": "\n".join(user_messages),
            "conversation_length": len(self.conversation_history)
        }
    
    def should_search_docs(self):
        """AI decides if documentation search is needed"""
        if not client or not crawled_data:
            return False
            
        try:
            context = self.get_full_context()
            prompt = f"""
–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –∞—Å—É—É–ª—Ç: {self.user_message}
–•–∞—Ä–∏–ª—Ü–ª–∞–≥—ã–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç: {context['full_conversation'][-500:]}

–≠–Ω—ç –∞—Å—É—É–ª—Ç–∞–¥ —Ö–∞—Ä–∏—É–ª–∞—Ö—ã–Ω —Ç—É–ª–¥ –±–∞—Ä–∏–º—Ç –±–∏—á–≥—ç—ç—Å —Ö–∞–π–ª—Ç —Ö–∏–π—Ö —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π —é—É?

'yes' —ç—Å–≤—ç–ª 'no' –≥—ç–∂ —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É.
            """
            
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "–¢–∞ —Ö–∞–π–ª—Ç—ã–Ω —à–∞–∞—Ä–¥–ª–∞–≥—ã–≥ —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–¥–æ–≥ –º—ç—Ä–≥—ç–∂–∏–ª—Ç—ç–Ω."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=10,
                temperature=0.2
            )
            
            return response.choices[0].message.content.strip().lower() == "yes"
        except:
            # Fallback: search if message contains technical terms
            tech_indicators = ["—Ö—ç—Ä—Ö—ç–Ω", "—è–∞–∂", "install", "setup", "config", "—Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö", "—Å—É—É–ª–≥–∞—Ö"]
            return any(indicator in self.user_message.lower() for indicator in tech_indicators)

def get_enhanced_ai_response(ai_context: AIContext):
    """Enhanced conversational AI that prioritizes docs search but falls back intelligently"""
    
    if not client:
        return "üîë OpenAI API —Ç“Ø–ª—Ö“Ø“Ø—Ä —Ç–æ—Ö–∏—Ä—É—É–ª–∞–≥–¥–∞–∞–≥“Ø–π –±–∞–π–Ω–∞. –ê–¥–º–∏–Ω—Ç–∞–π —Ö–æ–ª–±–æ–≥–¥–æ–Ω–æ —É—É."
    
    context_info = ai_context.get_full_context()
    
    # Step 1: Smart document search with enhanced accuracy
    doc_context = ""
    search_results = []
    found_in_docs = False
    
    if crawled_data:
        search_results = search_in_crawled_data(ai_context.user_message, max_results=5)
        
        # Enhanced filtering - only use high precision results
        high_precision_results = [r for r in search_results if r.get('precision_level') == 'high']
        
        if high_precision_results:
            found_in_docs = True
            ai_context.search_results = high_precision_results
            
            relevant_pages = []
            for result in high_precision_results:
                page = next((p for p in crawled_data if p['url'] == result['url']), None)
                if page:
                    image_info = ""
                    if page.get('images'):
                        image_info = "\n–ó—É—Ä–≥—É—É–¥:\n" + "\n".join([
                            f"- {img['alt']}: {img['url']}" if img['alt'] else f"- {img['url']}"
                            for img in page['images'][:3]  # Limit to 3 images
                        ])
                    
                    relevant_pages.append(
                        f"üìÑ {result['title']}\n"
                        f"üîó {result['url']}\n"
                        f"üìù {result['snippet']}\n"
                        f"üéØ –ù–∞—Ä–∏–π–≤—á–ª–∞–ª: {result['relevance_score']}/15\n"
                        f"{image_info}\n"
                    )
            doc_context = "\n".join(relevant_pages)
    
    # Step 2: Adaptive system prompt based on search results
    if found_in_docs:
        personality = """–¢–∞ Cloud.mn-–∏–π–Ω –±–∞—Ä–∏–º—Ç –±–∏—á–≥–∏–π–Ω –º—ç—Ä–≥—ç–∂–ª–∏–π–Ω —Ç—É—Å–ª–∞—Ö. 
        –ë–∞—Ä–∏–º—Ç –±–∏—á–≥–∏–π–Ω –º—ç–¥—ç—ç–ª–ª–∏–π–≥ –∞—à–∏–≥–ª–∞–Ω –ú–ê–® –ù–ê–†–ò–ô–í–ß–õ–ê–õ–¢–ê–ô, –¢–û–í–ß, –¢–û–î–û–†–•–û–ô —Ö–∞—Ä–∏—É–ª—Ç ”©–≥–Ω”©.
        –•–∞—Ä–∏—É–ª—Ç–∞–∞ –±“Ø—Ç—ç—Ü—Ç—ç–π –±–∞–π–ª–≥–∞–∂, —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–¥ —à—É—É–¥ —Ö—ç—Ä—ç–≥–ª—ç–∂ –±–æ–ª–æ—Ö –∑–∞–∞–≤–∞—Ä—á–∏–ª–≥–∞–∞ ”©–≥–Ω”©."""
    else:
        personality = """–¢–∞ Cloud.mn-–∏–π–Ω —É—Ö–∞–∞–ª–∞–≥ AI —Ç—É—Å–ª–∞—Ö. –ë–∞—Ä–∏–º—Ç –±–∏—á–∏–≥—Ç –æ–ª–¥–æ—Ö–≥“Ø–π –∞—Å—É—É–ª—Ç—É—É–¥–∞–¥ 
        ”©”©—Ä–∏–π–Ω –º—ç–¥–ª—ç–≥—ç—ç—Ä—ç—ç —Ö–∞—Ä–∏—É–ª–∂, —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π –±–æ–ª –¥—ç–º–∂–ª—ç–≥–∏–π–Ω –±–∞–≥—Ç —É–ª–∞–º–∂–ª–∞–Ω–∞."""
    
    system_content = f"""{personality}
    
“Æ–ù–î–°–≠–ù –ó–ê–†–ß–ò–ú: –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —Ç–æ–¥–æ—Ä—Ö–æ–π, –ø—Ä–∞–∫—Ç–∏–∫ —Ö–∞—Ä–∏—É–ª—Ç ”©–≥–Ω”©.

–û–¥–æ–æ–≥–∏–π–Ω –Ω”©—Ö—Ü”©–ª –±–∞–π–¥–∞–ª:
- –ë–∞—Ä–∏–º—Ç –±–∏—á–≥—ç—ç—Å –æ–ª–¥—Å–æ–Ω: {'–¢–∏–π–º' if found_in_docs else '“Æ–≥“Ø–π'}
- –•–∞—Ä–∏–ª—Ü–ª–∞–≥—ã–Ω —Ç“Ø“Ø—Ö: {context_info["conversation_length"]} –º–µ—Å—Å—ç–∂
- –ö–æ–Ω—Ç–µ–∫—Å—Ç—ã–Ω —Ö—ç–º–∂—ç—ç: {len(context_info['full_conversation'])} —Ç—ç–º–¥—ç–≥—Ç

–•–ê–†–ò–£–õ–¢–´–ù –ó–ê–ì–í–ê–†:
1. –•–∞—Ä–∏—É–ª—Ç—ã–≥ {200 if found_in_docs else 150} “Ø–≥—ç—ç—Å –±–∞–≥–∞–≥“Ø–π –±–∞–π–ª–≥–∞—Ö
2. –ü—Ä–∞–∫—Ç–∏–∫ –∞–ª—Ö–∞–º –∞–ª—Ö–º–∞–∞—Ä –∑–∞–∞–≤–∞—Ä—á–∏–ª–≥–∞–∞ ”©–≥”©—Ö  
3. –•–æ–ª–±–æ–≥–¥–æ—Ö –ª–∏–Ω–∫ –±–æ–ª–æ–Ω –¥—ç–º–∂–ª—ç–≥ —Å–∞–Ω–∞–ª –±–æ–ª–≥–æ—Ö
4. –¢–µ—Ö–Ω–∏–∫–∏–π–Ω –Ω—ç—Ä —Ç–æ–º—ä—ë–æ–≥ –º–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —Ç–∞–π–ª–±–∞—Ä–ª–∞—Ö

{'–ë–ê–†–ò–ú–¢ –ë–ò–ß–ì–ò–ô–ù –ú–≠–î–≠–≠–õ–≠–õ:\n' + doc_context if doc_context else ''}
    """
    
    # Step 3: Build conversation with smart context management
    messages = [{"role": "system", "content": system_content}]
    
    # Add relevant conversation history
    history_limit = 3 if found_in_docs else 5
    recent_messages = []
    for msg in context_info["user_messages"][-history_limit:]:
        if msg != ai_context.user_message:
            recent_messages.append({"role": "user", "content": msg})
    
    messages.extend(recent_messages)
    messages.append({"role": "user", "content": ai_context.user_message})
    
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            max_tokens=800 if found_in_docs else 600,
            temperature=0.4 if found_in_docs else 0.6
        )
        
        ai_response = response.choices[0].message.content
        ai_context.ai_response = ai_response
        ai_context.found_in_docs = found_in_docs
        
        # Store in memory
        if ai_context.conv_id not in conversation_memory:
            conversation_memory[ai_context.conv_id] = []
        
        conversation_memory[ai_context.conv_id].append({"role": "user", "content": ai_context.user_message})
        conversation_memory[ai_context.conv_id].append({"role": "assistant", "content": ai_response})
        
        # Keep only last 10 messages for better context
        if len(conversation_memory[ai_context.conv_id]) > 10:
            conversation_memory[ai_context.conv_id] = conversation_memory[ai_context.conv_id][-10:]
            
        return ai_response
        
    except Exception as e:
        logging.error(f"Enhanced AI response failed: {e}")
        return f"üîß AI —Å–∏—Å—Ç–µ–º—Ç—ç–π —Ö–æ–ª–±–æ–≥–¥–æ—Ö–æ–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞.\n\n–¢–∞ –¥–∞—Ä–∞–∞—Ö –∞—Ä–≥—É—É–¥–∞–∞—Ä —Ç—É—Å–ª–∞–º–∂ –∞–≤—á –±–æ–ª–Ω–æ:\n‚Ä¢ –ê—Å—É—É–ª—Ç—ã–≥ –¥–∞—Ö–∏–Ω —Ç–æ–¥–æ—Ä—Ö–æ–π –∞—Å—É—É—Ö\n‚Ä¢ '—Ç—É—Å–ª–∞–º–∂' –≥—ç–∂ –±–∏—á–∏—Ö\n\n–ê–ª–¥–∞–∞–Ω—ã –º—ç–¥—ç—ç–ª—ç–ª: {str(e)[:100]}"

def send_enhanced_teams_notification(ai_context: AIContext, problems_analysis: dict):
    """Enhanced Teams notification with detailed problem breakdown - focus on problems"""
    if not TEAMS_WEBHOOK_URL or not problems_analysis:
        return False
        
    try:
        conv_info = get_conversation_info(ai_context.conv_id)
        if not conv_info:
            return False
            
        contact = conv_info.get("contact", {})
        contact_name = contact.get("name", "–•—ç—Ä—ç–≥–ª—ç–≥—á")
        contact_email = contact.get("email", "–ò–º—ç–π–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π")
        
        overall = problems_analysis.get("overall_analysis", {})
        problems = problems_analysis.get("problems", [])
        
        # Create focused problem descriptions
        problems_text = ""
        for i, problem in enumerate(problems, 1):
            priority_emoji = "üî¥" if problem['priority'] == 'high' else "üü°" if problem['priority'] == 'medium' else "üü¢"
            category_emoji = "‚öôÔ∏è" if problem['category'] == 'technical' else "üíº" if problem['category'] == 'service_request' else "‚ùì"
            complexity_emoji = "üî•" if problem['complexity'] == 'complex' else "‚ö°" if problem['complexity'] == 'moderate' else "‚úÖ"
            
            problems_text += f"""
{priority_emoji} **–ê—Å—É—É–¥–∞–ª {i}:** {problem['title']}
{category_emoji} **–¢”©—Ä”©–ª:** {problem['category']}
{complexity_emoji} **–¢”©–≤”©–≥—Ç—ç–π –±–∞–π–¥–∞–ª:** {problem['complexity']}
üìã **–î—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π:** {problem['description']}
"""
        
        # Get only the most relevant conversation context (last user message + key context)
        context_info = ai_context.get_full_context()
        latest_user_message = ai_context.user_message
        
        # Create a concise summary instead of full conversation
        conversation_summary = ""
        if len(context_info['user_messages']) > 1:
            conversation_summary = f"‚Ä¢ ”®–º–Ω”©—Ö –∞—Å—É—É–ª—Ç—É—É–¥: {len(context_info['user_messages']) - 1}\n"
        conversation_summary += f"‚Ä¢ –û–¥–æ–æ–≥–∏–π–Ω –∞—Å—É—É–ª—Ç: {latest_user_message[:200]}{'...' if len(latest_user_message) > 200 else ''}"
        
        # Create streamlined Teams message focused on problems
        teams_message = f"""
üö® **–¢–ï–•–ù–ò–ö–ò–ô–ù –î–≠–ú–ñ–õ–≠–ì –®–ê–ê–†–î–õ–ê–ì–ê–¢–ê–ô**

üë§ **–•—ç—Ä—ç–≥–ª—ç–≥—á:** {contact_name}
üìß **–ò–º—ç–π–ª:** {contact_email}
üÜî **Conversation ID:** {ai_context.conv_id}

üìä **–ï—Ä”©–Ω—Ö–∏–π “Ø–Ω—ç–ª–≥—ç—ç:**
‚Ä¢ –ß—É—Ö–∞–ª –±–∞–π–¥–∞–ª: {'üî¥ ”®–Ω–¥”©—Ä' if overall.get('is_critical') else 'üü° –î—É–Ω–¥'}
‚Ä¢ –ò—Ç–≥—ç–ª–∏–π–Ω —Ç“Ø–≤—à–∏–Ω: {overall.get('confidence', 0)}%
‚Ä¢ –ë–∞—Ä–∏–º—Ç –±–∏—á–∏–≥—Ç –æ–ª–¥—Å–æ–Ω: {'‚ùå “Æ–≥“Ø–π' if not overall.get('found_in_docs') else '‚úÖ –¢–∏–π–º'}

üîç **–ò–ª—Ä“Ø“Ø–ª—Å—ç–Ω –∞—Å—É—É–¥–ª—É—É–¥ ({len(problems)}):**
{problems_text}

üí¨ **–•–∞—Ä–∏–ª—Ü–ª–∞–≥—ã–Ω —Ö—É—Ä–∞–∞–Ω–≥—É–π:**
{conversation_summary}

ü§ñ **AI –¥“Ø–≥–Ω—ç–ª—Ç:**
{ai_context.ai_response[:250] if ai_context.ai_response else 'AI —Ö–∞—Ä–∏—É–ª—Ç –±–∞–π—Ö–≥“Ø–π'}{'...' if ai_context.ai_response and len(ai_context.ai_response) > 250 else ''}

üïí **–û–≥–Ω–æ–æ:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

üîó **Chatwoot –ª–∏–Ω–∫:** {CHATWOOT_BASE_URL}/app/accounts/{ACCOUNT_ID}/conversations/{ai_context.conv_id}
        """
        
        # Determine color based on priority
        color = "FF0000" if overall.get('is_critical') else "FF6B35"  # Red for critical, Orange for normal
        
        return send_to_teams(
            message=teams_message,
            title=f"üö® {contact_name} - {len(problems)} –∞—Å—É—É–¥–∞–ª –∏–ª—ç—Ä–ª—ç—ç",
            color=color,
            conv_id=ai_context.conv_id
        )
        
    except Exception as e:
        logging.error(f"Enhanced Teams notification failed: {e}")
        return False

# Legacy function for backward compatibility
def get_ai_response(user_message: str, conversation_id: int, context_data: list = None):
    """Legacy wrapper for backward compatibility"""
    ai_context = AIContext(conversation_id, user_message)
    return get_enhanced_ai_response(ai_context)

def search_in_crawled_data(query: str, max_results: int = 5):
    """Enhanced search with higher precision and better relevance scoring"""
    if not crawled_data:
        return []
    
    query_lower = query.lower()
    results = []
    scored_pages = []
    
    # Enhanced keyword extraction for better matching
    query_words = [w.strip() for w in query_lower.split() if len(w.strip()) > 2]
    
    for page in crawled_data:
        score = 0
        title = page['title'].lower()
        body = page['body'].lower()
        
        # Exact phrase matching (highest priority)
        if query_lower in body:
            score += 10
        if query_lower in title:
            score += 15
            
        # Title keyword matches (high priority)
        title_matches = sum(1 for word in query_words if word in title)
        score += title_matches * 5
        
        # Body keyword matches
        body_matches = sum(1 for word in query_words if word in body)
        score += body_matches * 2
        
        # Bonus for multiple word matches in close proximity
        if len(query_words) > 1:
            for i, word1 in enumerate(query_words):
                for word2 in query_words[i+1:]:
                    if word1 in body and word2 in body:
                        # Check if words are close together (within 50 characters)
                        pos1 = body.find(word1)
                        pos2 = body.find(word2)
                        if abs(pos1 - pos2) < 50:
                            score += 3
        
        # Technical terms bonus
        tech_terms = ['config', 'setup', 'install', '—Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö', '—Å—É—É–ª–≥–∞—Ö', 'server', '—Å–µ—Ä–≤–µ—Ä']
        if any(term in query_lower for term in tech_terms) and any(term in body for term in tech_terms):
            score += 3
            
        if score > 0:
            scored_pages.append((score, page))
    
    # Sort by score and get top results
    scored_pages.sort(key=lambda x: x[0], reverse=True)
    
    for score, page in scored_pages[:max_results]:
        # Find the most relevant snippet with better context
        body = page['body']
        best_snippet = ""
        max_context = 400
        
        # Try to find snippet containing multiple query words
        best_match_pos = -1
        max_word_matches = 0
        
        for i in range(0, len(body) - 100, 50):
            snippet_part = body[i:i+200].lower()
            word_matches = sum(1 for word in query_words if word in snippet_part)
            if word_matches > max_word_matches:
                max_word_matches = word_matches
                best_match_pos = i
        
        if best_match_pos >= 0:
            start = max(0, best_match_pos - 100)
            end = min(len(body), best_match_pos + 300)
            best_snippet = body[start:end].strip()
            if start > 0:
                best_snippet = "..." + best_snippet
            if end < len(body):
                best_snippet = best_snippet + "..."
        else:
            best_snippet = body[:max_context] + "..." if len(body) > max_context else body
            
        results.append({
            'title': page['title'],
            'url': page['url'],
            'snippet': best_snippet,
            'relevance_score': score,
            'precision_level': 'high' if score >= 8 else 'medium' if score >= 4 else 'low'
        })

    return results

def scrape_single(url: str):
    resp = requests.get(url, timeout=10)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")
    title = soup.title.string.strip() if soup.title else url
    body, images = extract_content(soup, url)
    return {"url": url, "title": title, "body": body, "images": images}


# ‚Äî‚Äî AI Analysis Functions ‚Äî‚Äî #
def analyze_user_message_with_ai(user_message: str, ai_response: str, conv_id: int):
    """Legacy wrapper for backward compatibility - now uses enhanced analysis"""
    ai_context = AIContext(conv_id, user_message)
    ai_context.ai_response = ai_response
    analysis = analyze_conversation_for_problems(ai_context)
    
    if analysis:
        # Convert new format to legacy format for compatibility
        problems = analysis.get("problems", [])
        overall = analysis.get("overall_analysis", {})
        
        return {
            "needs_support": overall.get("needs_support", False),
            "problem_description": problems[0]["description"] if problems else user_message[:50] + "...",
            "core_problem": problems[0]["title"] if problems else user_message[:50] + "...",
            "matching_services": [],  # This is now handled by smart service detection
            "confidence": overall.get("confidence", 0),
            "is_critical": overall.get("is_critical", False)
        }
    
    return {
        "needs_support": False,
        "problem_description": user_message[:50] + "..." if len(user_message) > 50 else user_message,
        "core_problem": user_message[:50] + "..." if len(user_message) > 50 else user_message,
        "matching_services": [],
        "confidence": 0,
        "is_critical": False
    }

def analyze_conversation_for_problems(ai_context: AIContext):
    """Enhanced AI analysis to identify multiple specific problems"""
    if not client:
        return None
    
    try:
        context_info = ai_context.get_full_context()
        
        # Enhanced problem analysis prompt
        analysis_prompt = f"""
–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –±“Ø—Ö —Ö–∞—Ä–∏–ª—Ü–ª–∞–≥–∞: {context_info['full_conversation']}
AI —Ö–∞—Ä–∏—É–ª—Ç: {ai_context.ai_response}

–≠–Ω—ç —Ö–∞—Ä–∏–ª—Ü–ª–∞–≥—ã–≥ –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–∂ –¥–∞—Ä–∞–∞—Ö –∞–∂–ª—É—É–¥—ã–≥ –≥“Ø–π—Ü—ç—Ç–≥—ç:

1. –ê–°–£–£–î–õ–£–£–î–´–ì —è–ª–≥–∞–∂ —Ç–æ–¥–æ—Ä—Ö–æ–π–ª (—Ö—ç—Ä—ç–≤ –æ–ª–æ–Ω –∞—Å—É—É–¥–∞–ª –±–∞–π–≤–∞–ª —Ç—É—Å —Ç—É—Å–∞–¥ –Ω—å)
2. –¢–µ—Ö–Ω–∏–∫–∏–π–Ω –Ω–∞—Ä–∏–π–≤—á–ª–∞–ª—ã–Ω —Ç“Ø–≤—à–∏–Ω–≥ “Ø–Ω—ç–ª—ç  
3. –î—ç–º–∂–ª—ç–≥–∏–π–Ω —à–∞–∞—Ä–¥–ª–∞–≥—ã–≥ —Ç–æ–¥–æ—Ä—Ö–æ–π–ª
4. Microsoft Teams —Ä—É—É –∏–ª–≥—ç—ç—Ö —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π —ç—Å—ç—Ö–∏–π–≥ —à–∏–π–¥

JSON —Ö—ç–ª–±—ç—Ä—ç—ç—Ä —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É:
{{
    "problems": [
        {{
            "title": "–∞—Å—É—É–¥–ª—ã–Ω —Ç–æ–≤—á –Ω—ç—Ä",
            "description": "–¥—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π —Ç–∞–π–ª–±–∞—Ä", 
            "category": "technical/general/service_request",
            "priority": "high/medium/low",
            "complexity": "simple/moderate/complex"
        }}
    ],
    "overall_analysis": {{
        "needs_support": true/false,
        "is_critical": true/false,
        "confidence": 0-100,
        "user_satisfaction": "high/medium/low",
        "requires_teams_notification": true/false,
        "found_in_docs": {getattr(ai_context, 'found_in_docs', False)}
    }},
    "recommended_action": "continue_chat/escalate_to_support/provide_service_info/mark_resolved"
}}
        """
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": "–¢–∞ –º—ç—Ä–≥—ç–∂–ª–∏–π–Ω —Ç–µ—Ö–Ω–∏–∫–∏–π–Ω –¥—ç–º–∂–ª—ç–≥–∏–π–Ω —à–∏–Ω–∂—ç—ç—á. –ê—Å—É—É–¥–ª—É—É–¥—ã–≥ —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–∂, —à–∏–π–¥–≤—ç—Ä–ª—ç—Ö –∞—Ä–≥–∞ –∑–∞–º—ã–≥ —Å–∞–Ω–∞–ª –±–æ–ª–≥–æ–¥–æ–≥."
                },
                {
                    "role": "user",
                    "content": analysis_prompt
                }
            ],
            max_tokens=500,
            temperature=0.3
        )
        
        analysis_text = response.choices[0].message.content.strip()
        json_match = re.search(r'\{.*\}', analysis_text, re.DOTALL)
        
        if json_match:
            analysis_result = json.loads(json_match.group())
            ai_context.analysis_result = analysis_result
            return analysis_result
        
        return None
        
    except Exception as e:
        logging.error(f"Enhanced problem analysis failed: {e}")
        return None

def suggest_services_from_analysis(matching_services: list):
    """Generate intelligent service suggestions based on analysis"""
    if not matching_services:
        return ""
    
    suggestions = "üí° **–¢–∞–Ω—ã –∞—Å—É—É–¥–∞–ª—Ç–∞–π —Ö–æ–ª–±–æ–æ—Ç–æ–π “Ø–π–ª—á–∏–ª–≥—ç—ç–Ω“Ø“Ø–¥:**\n\n"
    
    for service_name in matching_services:
        if service_name in SERVICE_PRICES:
            service_info = SERVICE_PRICES[service_name]
            suggestions += f"üîß **{service_name}**\n"
            suggestions += f"   üí∞ “Æ–Ω—ç: {service_info['price']}\n"
            suggestions += f"   üìù –¢–∞–π–ª–±–∞—Ä: {service_info['desc']}\n\n"
    
    suggestions += "üìû –≠–¥–≥—ç—ç—Ä “Ø–π–ª—á–∏–ª–≥—ç—ç–Ω–∏–π —Ç–∞–ª–∞–∞—Ä –¥—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π –º—ç–¥—ç—ç–ª—ç–ª –∞–≤–∞—Ö—ã–≥ —Ö“Ø—Å–≤—ç–ª '–¥—ç–º–∂–ª—ç–≥' –≥—ç–∂ –±–∏—á–Ω—ç “Ø“Ø."
    return suggestions

def smart_service_detection(ai_context: AIContext):
    """Smart service detection using AI context"""
    if not client:
        return []
    
    try:
        context_info = ai_context.get_full_context()
        service_list = "\n".join([f"- {key}" for key in SERVICE_PRICES.keys()])
        
        detection_prompt = f"""
–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω —Ö–∞—Ä–∏–ª—Ü–ª–∞–≥–∞: {context_info['full_conversation']}
AI —Ö–∞—Ä–∏—É–ª—Ç: {ai_context.ai_response or ''}

–ë–æ–ª–æ–º–∂—Ç–æ–π “Ø–π–ª—á–∏–ª–≥—ç—ç–Ω“Ø“Ø–¥:
{service_list}

–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –∞—Å—É—É–¥–∞–ª—Ç–∞–π —Ö–∞–º–≥–∏–π–Ω —Ç–æ—Ö–∏—Ä–æ—Ö “Ø–π–ª—á–∏–ª–≥—ç—ç–Ω“Ø“Ø–¥–∏–π–≥ –∂–∞–≥—Å–∞–∞–Ω–∞ —É—É:

JSON —Ö—ç–ª–±—ç—Ä—ç—ç—Ä —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É:
{{
    "matching_services": ["“Ø–π–ª—á–∏–ª–≥—ç—ç–Ω–∏–π –∂–∞–≥—Å–∞–∞–ª—Ç"],
    "confidence": 0-100
}}
        """
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": "–¢–∞ “Ø–π–ª—á–∏–ª–≥—ç—ç–Ω–∏–π —Ç–æ—Ö–∏—Ä–ª—ã–≥ —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö –º—ç—Ä–≥—ç–∂–∏–ª—Ç—ç–Ω."
                },
                {
                    "role": "user",
                    "content": detection_prompt
                }
            ],
            max_tokens=150,
            temperature=0.2
        )
        
        result = response.choices[0].message.content.strip()
        json_match = re.search(r'\{.*\}', result, re.DOTALL)
        
        if json_match:
            detection_result = json.loads(json_match.group())
            return detection_result.get("matching_services", [])
        
        return []
        
    except Exception as e:
        logging.error(f"Smart service detection failed: {e}")
        return []

# ‚Äî‚Äî Enhanced Chatwoot Integration ‚Äî‚Äî #
def send_to_chatwoot(conv_id: int, content: str, message_type: str = "outgoing"):
    """Enhanced chatwoot message sending with better error handling"""
    api_url = (
        f"{CHATWOOT_BASE_URL}/api/v1/accounts/{ACCOUNT_ID}"
        f"/conversations/{conv_id}/messages"
    )
    headers = {
        "api_access_token": CHATWOOT_API_KEY,
        "Content-Type": "application/json"
    }
    payload = {
        "content": content, 
        "message_type": message_type,
        "private": False
    }
    
    try:
        resp = requests.post(api_url, json=payload, headers=headers, timeout=10)
        resp.raise_for_status()
        logging.info(f"Message sent to conversation {conv_id}")
        return True
    except Exception as e:
        logging.error(f"Failed to send message to chatwoot: {e}")
        return False

def get_conversation_info(conv_id: int):
    """Get conversation details from Chatwoot"""
    api_url = f"{CHATWOOT_BASE_URL}/api/v1/accounts/{ACCOUNT_ID}/conversations/{conv_id}"
    headers = {"api_access_token": CHATWOOT_API_KEY}
    
    try:
        resp = requests.get(api_url, headers=headers, timeout=10)
        resp.raise_for_status()
        return resp.json()
    except Exception as e:
        logging.error(f"Failed to get conversation info: {e}")
        return None

def mark_conversation_resolved(conv_id: int):
    """Mark conversation as resolved"""
    api_url = f"{CHATWOOT_BASE_URL}/api/v1/accounts/{ACCOUNT_ID}/conversations/{conv_id}/toggle_status"
    headers = {"api_access_token": CHATWOOT_API_KEY}
    payload = {"status": "resolved"}
    
    try:
        resp = requests.post(api_url, json=payload, headers=headers, timeout=10)
        resp.raise_for_status()
        return True
    except Exception as e:
        logging.error(f"Failed to mark conversation as resolved: {e}")
        return False


# ‚Äî‚Äî Teams Integration ‚Äî‚Äî #
def send_to_teams(message: str, title: str = "Cloud.mn AI Assistant", color: str = "0076D7", conv_id: int = None):
    """Send message to Microsoft Teams channel using webhook"""
    if not TEAMS_WEBHOOK_URL:
        logging.warning("Teams webhook URL not configured")
        return False
        
    try:
        sections = [
            {
                "activityTitle": title,
                "activitySubtitle": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "text": message,
                "markdown": True
            }
        ]
        
        # Add Chatwoot URL section if conv_id is provided
        if conv_id:
            sections.append({
                "text": f"<a href='{CHATWOOT_BASE_URL}/app/accounts/{ACCOUNT_ID}/conversations/{conv_id}'>Chatwoot –¥—ç—ç—Ä —Ö–∞—Ä–∞—Ö</a>",
                "markdown": False
            })
        
        payload = {
            "@type": "MessageCard",
            "@context": "http://schema.org/extensions",
            "themeColor": color,
            "summary": title,
            "sections": sections
        }
        
        response = requests.post(
            TEAMS_WEBHOOK_URL,
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=10
        )
        response.raise_for_status()
        logging.info("Message sent to Teams successfully")
        return True
        
    except Exception as e:
        logging.error(f"Failed to send message to Teams: {e}")
        return False

def send_teams_notification(conv_id: int, message: str, message_type: str = "outgoing", is_unsolved: bool = False, confirmed: bool = False, user_email: str = None, original_question: str = ""):
    """Send notification to Teams about core problems only (confirmed critical issues)"""
    if not TEAMS_WEBHOOK_URL:
        return
        
    try:
        # Get conversation info
        conv_info = get_conversation_info(conv_id)
        if not conv_info:
            return
            
        contact = conv_info.get("contact", {})
        contact_name = contact.get("name", "–•—ç—Ä—ç–≥–ª—ç–≥—á")
        contact_email = contact.get("email", "–ò–º—ç–π–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π")
        
        # Only send to Teams if confirmed and there's a specific problem
        if confirmed and user_email:
            # Get email from conversation or use contact email as fallback
            display_email = user_email if user_email else contact_email
            
            # Analyze the entire conversation to identify the core issue
            conversation_history = conversation_memory.get(conv_id, [])
            user_messages = []
            for msg in conversation_history:
                if msg.get("role") == "user":
                    user_messages.append(msg.get("content", ""))
            
            # Get core problem using AI analysis
            core_problem = ""
            if original_question and client:
                try:
                    # Use the full conversation context to get precise problem description
                    full_context = "\n".join(user_messages) if user_messages else original_question
                    
                    problem_analysis = client.chat.completions.create(
                        model="gpt-4",
                        messages=[
                            {
                                "role": "system",
                                "content": "–¢–∞ —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –∞—Å—É—É–¥–ª—ã–≥ —Ü—ç–≥—Ü—Ç—ç–π —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–∂ ”©–≥”©—Ö –º—ç—Ä–≥—ç–∂–∏–ª—Ç—ç–Ω. –î—ç–º–∂–ª—ç–≥–∏–π–Ω –±–∞–≥—Ç –æ–π–ª–≥–æ–º–∂—Ç–æ–π, “Ø–π–ª–¥—ç–ª–¥ —á–∏–≥–ª—ç—Å—ç–Ω —Ç–∞–π–ª–±–∞—Ä ”©–≥."
                            },
                            {
                                "role": "user",
                                "content": f"–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –±“Ø—Ö —Ö–∞—Ä–∏–ª—Ü–ª–∞–≥–∞: '{full_context}'\n\n–≠–Ω—ç —Ö—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –•–ê–ú–ì–ò–ô–ù –ß–£–•–ê–õ –∞—Å—É—É–¥–ª—ã–≥ 1 ”©–≥“Ø“Ø–ª–±—ç—Ä—ç—ç—Ä —Ç–æ–¥–æ—Ä—Ö–æ–π —Ç–∞–π–ª–±–∞—Ä–ª–∞–∂, –¥—ç–º–∂–ª—ç–≥–∏–π–Ω –±–∞–≥—Ç —Ö—ç—Ä—Ö—ç–Ω —à–∏–π–¥–≤—ç—Ä–ª—ç—Ö —Ç–∞–ª–∞–∞—Ä –º—ç–¥—ç—ç–ª—ç–ª ”©–≥:"
                            }
                        ],
                        max_tokens=100,
                        temperature=0.2
                    )
                    core_problem = problem_analysis.choices[0].message.content.strip()
                except Exception as e:
                    logging.error(f"Core problem analysis failed: {e}")
                    core_problem = original_question[:100] + "..." if len(original_question) > 100 else original_question
            else:
                core_problem = original_question[:100] + "..." if len(original_question) > 100 else original_question
            
            # Create focused Teams message with only essential information
            teams_message = f"""
üö® –ß–£–•–ê–õ –ê–°–£–£–î–ê–õ - Cloud.mn

üë§ –•—ç—Ä—ç–≥–ª—ç–≥—á: {contact_name}
üìß –ò–º—ç–π–ª: {display_email}
üÜî Conversation ID: {conv_id}

‚ö†Ô∏è **–ê—Å—É—É–¥–∞–ª:**
{core_problem}

üïí –û–≥–Ω–æ–æ: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
üîó Chatwoot: {CHATWOOT_BASE_URL}/app/accounts/{ACCOUNT_ID}/conversations/{conv_id}
            """
            
            # Send to Teams with critical color (red/orange)
            send_to_teams(
                message=teams_message,
                title=f"üö® –ß–£–•–ê–õ - {contact_name}",
                color="FF6B35",  # Orange/red color for critical issues
                conv_id=conv_id
            )
            
            logging.info(f"Critical issue sent to Teams for conversation {conv_id}")
        
    except Exception as e:
        logging.error(f"Failed to send Teams notification: {e}")

def get_conversation_history(conv_id: int, max_messages: int = 5):
    """Get recent conversation history"""
    try:
        memory = conversation_memory.get(conv_id, [])
        if not memory:
            return "–•–∞—Ä–∏–ª—Ü–∞–Ω —è—Ä–∏–∞–Ω—ã —Ç“Ø“Ø—Ö –æ–ª–¥—Å–æ–Ω–≥“Ø–π"
            
        history = []
        for msg in memory[-max_messages:]:
            role = "üë§ –•—ç—Ä—ç–≥–ª—ç–≥—á" if msg["role"] == "user" else "ü§ñ AI"
            history.append(f"{role}: {msg['content']}")
            
        return "\n\n".join(history)
    except Exception as e:
        logging.error(f"Failed to get conversation history: {e}")
        return "–•–∞—Ä–∏–ª—Ü–∞–Ω —è—Ä–∏–∞–Ω—ã —Ç“Ø“Ø—Ö–∏–π–≥ –∞—á–∞–∞–ª–∞—Ö–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞"


# ‚Äî‚Äî API Endpoints ‚Äî‚Äî #
@app.route("/api/scrape", methods=["POST"])
def api_scrape():
    data = request.get_json(force=True)
    url = data.get("url")
    if not url:
        return jsonify({"error": "Missing 'url' in JSON body"}), 400
    try:
        page = scrape_single(url)
        return jsonify(page)
    except Exception as e:
        return jsonify({"error": f"Fetch/Scrape failed: {e}"}), 502

@app.route("/api/crawl", methods=["POST"])
def api_crawl():
    pages = crawl_and_scrape(ROOT_URL)
    return jsonify(pages)


# ‚Äî‚Äî Enhanced Chatwoot Webhook ‚Äî‚Äî #
@app.route("/webhook/chatwoot", methods=["POST"])
def chatwoot_webhook():
    """Enhanced conversational webhook - ChatGPT style interaction"""
    global crawled_data, crawl_status
    
    data = request.json or {}
    
    # Only process incoming messages
    if data.get("message_type") != "incoming":
        return jsonify({}), 200

    conv_id = data["conversation"]["id"]
    text = data.get("content", "").strip()
    contact = data.get("conversation", {}).get("contact", {})
    contact_name = contact.get("name", "–•—ç—Ä—ç–≥–ª—ç–≥—á")

    logging.info(f"Received message from {contact_name} in conversation {conv_id}: {text}")

    # Auto-crawl status check
    if crawl_status["status"] == "not_started" and AUTO_CRAWL_ON_START:
        auto_crawl_on_startup()

    # Handle special commands (minimal, only essential ones)
    if text.lower() in ["—Ç—É—Å–ª–∞–º–∂", "help", "—Ç—É—Å–ª–∞—Ö"]:
        help_text = f"""
üëã –°–∞–π–Ω –±–∞–π–Ω–∞ —É—É {contact_name}! –ë–∏ Cloud.mn-–∏–π–Ω AI —Ç—É—Å–ª–∞—Ö.

üìä **–¢”©–ª”©–≤:**
{'‚úÖ –ë–∞—Ä–∏–º—Ç –±–∏—á–∏–≥ –±—ç–ª—ç–Ω –±–∞–π–Ω–∞' if crawl_status["status"] == "completed" else 'üîÑ –°–∏—Å—Ç–µ–º–∏–π–≥ –±—ç–ª—Ç–≥—ç–∂ –±–∞–π–Ω–∞...'}

üí¨ **–•—ç—Ä—Ö—ç–Ω –∞—à–∏–≥–ª–∞—Ö:**
‚Ä¢ –ê—Å—É—É–ª—Ç–∞–∞ —ç—Å–≤—ç–ª –∞—Å—É—É–¥–ª–∞–∞ —ç–Ω–≥–∏–π–Ω —Ö—ç–ª—ç—ç—Ä –±–∏—á–Ω—ç “Ø“Ø
‚Ä¢ –ë–∏ —ç—Ö–ª—ç—ç–¥ docs.cloud.mn-–∞–∞—Å —Ö–∞–π–∂, —Ö–∞—Ä–∏—É–ª–Ω–∞
‚Ä¢ –û–ª–¥–æ—Ö–≥“Ø–π –±–æ–ª –º–∏–Ω–∏–π –º—ç–¥–ª—ç–≥—ç—ç—Ä —Ç—É—Å–ª–∞–Ω–∞
‚Ä¢ –®–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π –±–æ–ª –º—ç—Ä–≥—ç–∂–ª–∏–π–Ω –¥—ç–º–∂–ª—ç–≥—Ç —Ö–æ–ª–±–æ–∂ ”©–≥–Ω”©

üîß **–ñ–∏—à—ç—ç –∞—Å—É—É–ª—Ç—É—É–¥:**
‚Ä¢ "Docker —Ö—ç—Ä—Ö—ç–Ω —Å—É—É–ª–≥–∞—Ö –≤—ç?"
‚Ä¢ "Nginx —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö –∑–∞–∞–≤–∞—Ä —Ö—ç—Ä—ç–≥—Ç—ç–π"
‚Ä¢ "–°–µ—Ä–≤–µ—Ä–∏–π–Ω –∞–ª–¥–∞–∞ –≥–∞—Ä—á –±–∞–π–Ω–∞"

–ê—Å—É—É–ª—Ç–∞–∞ —á”©–ª”©”©—Ç—ç–π –±–∏—á—ç—ç—Ä—ç–π! üòä
        """
        send_to_chatwoot(conv_id, help_text)

    elif text.lower() in ["–±–∞—è—Ä—Ç–∞–π", "goodbye", "–±–∞–∞–π", "–¥—É—É—Å–ª–∞–∞"]:
        response = f"üëã –ë–∞—è—Ä—Ç–∞–π {contact_name}! –î–∞—Ä–∞–∞ –¥–∞—Ö–∏–Ω —Ç—É—Å–ª–∞–º–∂ —Ö—ç—Ä—ç–≥—Ç—ç–π –±–æ–ª —ç—Ä–≥—ç—ç–¥ –∏—Ä—ç—ç—Ä—ç–π!"
        send_to_chatwoot(conv_id, response)
        mark_conversation_resolved(conv_id)

    # Handle email confirmation workflows
    elif text.lower() in ["—Ü—É—Ü–ª–∞—Ö", "cancel", "“Ø–≥“Ø–π —Ü—É—Ü–ª–∞—Ö"]:
        memory = conversation_memory.get(conv_id, [])
        if memory and ("pending_confirmation" in memory[-1].get("content", "") or "waiting_for_email" in memory[-1].get("content", "")):
            send_to_chatwoot(conv_id, "‚úÖ –û–π–ª–≥–æ–ª–æ–æ. –•–∞—Ä–∏–ª—Ü–ª–∞–≥—ã–≥ “Ø—Ä–≥—ç–ª–∂–ª“Ø“Ø–ª—Ü–≥—ç—ç–µ.")
            # Clear waiting states
            conversation_memory[conv_id] = [msg for msg in conversation_memory[conv_id] 
                                         if not any(state in msg.get("content", "") for state in ["pending_confirmation", "waiting_for_email"])]
        else:
            # Handle as normal conversation
            process_conversational_message(conv_id, text, contact_name)

    else:
        # Check if this is a response to confirmation or email request
        memory = conversation_memory.get(conv_id, [])
        
        if memory and "pending_confirmation" in memory[-1].get("content", ""):
            handle_confirmation_response(conv_id, text, contact_name)
        elif memory and "waiting_for_email" in memory[-1].get("content", ""):
            handle_email_response(conv_id, text, contact_name)
        else:
            # Normal conversational interaction
            process_conversational_message(conv_id, text, contact_name)

    return jsonify({"status": "success"}), 200

def process_conversational_message(conv_id: int, text: str, contact_name: str):
    """Process normal conversational messages with enhanced AI"""
    
    # Create AI context
    ai_context = AIContext(conv_id, text)
    
    # Get enhanced AI response
    ai_response = get_enhanced_ai_response(ai_context)
    send_to_chatwoot(conv_id, ai_response)
    
    # Enhanced analysis and decision making
    analysis = analyze_conversation_for_problems(ai_context)
    
    if analysis:
        overall = analysis.get("overall_analysis", {})
        problems = analysis.get("problems", [])
        recommended_action = analysis.get("recommended_action", "continue_chat")
        
        # Log analysis for debugging
        logging.info(f"Analysis for conv {conv_id}: {len(problems)} problems, action: {recommended_action}, critical: {overall.get('is_critical', False)}")
        
        # Handle different scenarios based on analysis
        if overall.get("requires_teams_notification", False) or (overall.get("is_critical", False) and overall.get("needs_support", False)):
            # Send detailed Teams notification immediately for critical issues
            teams_sent = send_enhanced_teams_notification(ai_context, analysis)
            
            if teams_sent:
                confirmation_message = f"""
üö® –¢–∞–Ω—ã –∞—Å—É—É–¥–∞–ª –º—ç—Ä–≥—ç–∂–ª–∏–π–Ω –¥—ç–º–∂–ª—ç–≥–∏–π–Ω –±–∞–≥—Ç –∞–≤—Ç–æ–º–∞—Ç–∞–∞—Ä –∏–ª–≥—ç—ç–≥–¥–ª—ç—ç.

üìã **–ò–ª—Ä“Ø“Ø–ª—Å—ç–Ω –∞—Å—É—É–¥–ª—É—É–¥:** {len(problems)}
üìä **–ß—É—Ö–∞–ª –±–∞–π–¥–∞–ª:** {'üî¥ ”®–Ω–¥”©—Ä' if overall.get('is_critical') else 'üü° –î—É–Ω–¥ –∑—ç—Ä—ç–≥'}

–î—ç–º–∂–ª—ç–≥–∏–π–Ω –±–∞–≥ —Ç—É–Ω —É–¥–∞—Ö–≥“Ø–π —Ç–∞–Ω–∞–π –∞—Å—É—É–¥–ª—ã–≥ —à–∏–π–¥–≤—ç—Ä–ª—ç—Ö—ç—ç—Ä —Ö–æ–ª–±–æ–≥–¥–æ—Ö –±–æ–ª–Ω–æ.

”®”©—Ä –∞—Å—É—É–ª—Ç –±–∞–π–≤–∞–ª —á”©–ª”©”©—Ç—ç–π –∞—Å—É—É–≥–∞–∞—Ä–∞–π! üòä
                """
                send_to_chatwoot(conv_id, confirmation_message)
                
        elif recommended_action == "escalate_to_support" and overall.get("needs_support", False):
            # Ask for confirmation before escalating
            core_problem = problems[0]["title"] if problems else "–¢–µ—Ö–Ω–∏–∫–∏–π–Ω –∞—Å—É—É–¥–∞–ª"
            confirmation_message = f"""
ü§î –¢–∞–Ω—ã –∞—Å—É—É–¥–∞–ª: "{core_problem}"

–≠–Ω—ç –∞—Å—É—É–¥–ª—ã–≥ –º—ç—Ä–≥—ç–∂–ª–∏–π–Ω –¥—ç–º–∂–ª—ç–≥–∏–π–Ω –±–∞–≥—Ç —à–∏–ª–∂“Ø“Ø–ª—ç—Ö “Ø“Ø?

‚úÖ **–¢–∏–π–º** - –¥—ç–º–∂–ª—ç–≥–∏–π–Ω –±–∞–≥—Ç –∏–ª–≥—ç—ç—Ö
‚ùå **“Æ–≥“Ø–π** - —Ö–∞—Ä–∏–ª—Ü–ª–∞–≥—ã–≥ “Ø—Ä–≥—ç–ª–∂–ª“Ø“Ø–ª—ç—Ö

–¢–∞ —Å–æ–Ω–≥–æ–ª—Ç–æ–æ –±–∏—á–Ω—ç “Ø“Ø.
            """
            send_to_chatwoot(conv_id, confirmation_message)
            
            # Store confirmation state
            if conv_id not in conversation_memory:
                conversation_memory[conv_id] = []
            conversation_memory[conv_id].append({"role": "assistant", "content": confirmation_message + " pending_confirmation"})
                
        elif recommended_action == "provide_service_info":
            # Smart service suggestions
            services = smart_service_detection(ai_context)
            if services:
                service_suggestions = suggest_services_from_analysis(services)
                if service_suggestions:
                    send_to_chatwoot(conv_id, service_suggestions)
                    
        elif recommended_action == "mark_resolved" and overall.get("user_satisfaction") == "high":
            # Offer to close if user seems satisfied
            close_suggestion = f"""
‚úÖ –¢–∞–Ω—ã –∞—Å—É—É–ª—Ç —Ö–∞–Ω–≥–∞–ª—Ç—Ç–∞–π —Ö–∞—Ä–∏—É–ª–∞–≥–¥—Å–∞–Ω –±–æ–ª–æ–ª—Ç–æ–π!

”®”©—Ä –∞—Å—É—É–ª—Ç –±–∞–π–≤–∞–ª —á”©–ª”©”©—Ç—ç–π –∞—Å—É—É–≥–∞–∞—Ä–∞–π, —ç—Å–≤—ç–ª —Ö–∞—Ä–∏–ª—Ü–ª–∞–≥—ã–≥ –¥—É—É—Å–≥–∞—Ö—ã–≥ —Ö“Ø—Å–≤—ç–ª "–±–∞—è—Ä—Ç–∞–π" –≥—ç–∂ –±–∏—á–Ω—ç “Ø“Ø. üòä
            """
            send_to_chatwoot(conv_id, close_suggestion)

def handle_confirmation_response(conv_id: int, text: str, contact_name: str):
    """Handle user response to Teams escalation confirmation"""
    
    if not client:
        send_to_chatwoot(conv_id, "üîë AI —Å–∏—Å—Ç–µ–º –æ–¥–æ–æ–≥–æ–æ—Ä –±–æ–ª–æ–º–∂–≥“Ø–π –±–∞–π–Ω–∞. –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É.")
        return
    
    try:
        # Use AI to understand the response
        confirmation_response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": "–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω —Ö–∞—Ä–∏—É–ª—Ç—ã–≥ –¥“Ø–≥–Ω—ç–∂ –∑”©–≤—à”©”©—Ä”©–ª —ç—Å–≤—ç–ª —Ç–∞—Ç–≥–∞–ª–∑–ª—ã–≥ —Ç–æ–¥–æ—Ä—Ö–æ–π–ª. 'yes' —ç—Å–≤—ç–ª 'no' –≥—ç–∂ —Ö–∞—Ä–∏—É–ª–Ω–∞ —É—É."
                },
                {
                    "role": "user",
                    "content": f"–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω —Ö–∞—Ä–∏—É–ª—Ç: {text}\n\n–≠–Ω—ç –∑”©–≤—à”©”©—Ä”©–ª –º”©–Ω “Ø“Ø?"
                }
            ],
            max_tokens=10,
            temperature=0.2
        )
        
        is_confirmed = confirmation_response.choices[0].message.content.strip().lower() == "yes"
        
        if is_confirmed:
            # Request email
            email_request = f"""
‚úÖ –ë–∞—è—Ä–ª–∞–ª–∞–∞ {contact_name}!

–î—ç–º–∂–ª—ç–≥–∏–π–Ω –±–∞–≥—Ç —Ç–∞–Ω–∞–π –∞—Å—É—É–¥–ª—ã–≥ –∏–ª–≥—ç—ç—Ö–∏–π–Ω —Ç—É–ª–¥ email —Ö–∞—è–≥–∞–∞ –±–∏—á–Ω—ç “Ø“Ø?

üìß **–ñ–∏—à—ç—ç:** example@gmail.com

üí° –•—ç—Ä—ç–≤ email ”©–≥”©—Ö–≥“Ø–π –±–æ–ª "—Ü—É—Ü–ª–∞—Ö" –≥—ç–∂ –±–∏—á–Ω—ç “Ø“Ø.
            """
            send_to_chatwoot(conv_id, email_request)
            
            # Update conversation state
            conversation_memory[conv_id].append({"role": "assistant", "content": "waiting_for_email"})
        else:
            send_to_chatwoot(conv_id, f"‚úÖ –û–π–ª–≥–æ–ª–æ–æ {contact_name}. ”®”©—Ä –∞—Å—É—É–ª—Ç –±–∞–π–≤–∞–ª —á”©–ª”©”©—Ç—ç–π –∞—Å—É—É–≥–∞–∞—Ä–∞–π!")
            # Clear confirmation state
            conversation_memory[conv_id] = [msg for msg in conversation_memory[conv_id] 
                                         if "pending_confirmation" not in msg.get("content", "")]
            
    except Exception as e:
        logging.error(f"Error handling confirmation: {e}")
        send_to_chatwoot(conv_id, "üîß –°–∏—Å—Ç–µ–º–∏–π–Ω –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞. –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É.")

def handle_email_response(conv_id: int, text: str, contact_name: str):
    """Handle user email input"""
    
    import re
    
    # Validate email format
    email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    
    if re.match(email_pattern, text.strip()):
        user_email = text.strip()
        
        # Get the conversation context for Teams
        memory = conversation_memory.get(conv_id, [])
        
        # Find the original problem context
        original_question = ""
        ai_response = ""
        
        # Look for the AI response before email collection started
        for i, msg in enumerate(memory):
            if "waiting_for_email" in msg.get("content", ""):
                # Find previous user and AI messages
                if i >= 2:
                    ai_response = memory[i-2].get("content", "")
                    if i >= 3:
                        original_question = memory[i-3].get("content", "")
                break
        
        # Create enhanced AI context for Teams notification
        ai_context = AIContext(conv_id, original_question or "Email —Ö–æ–ª–±–æ–≥–¥–æ—Ö —Ö“Ø—Å—ç–ª—Ç")
        ai_context.ai_response = ai_response
        
        # Analyze the conversation for detailed Teams notification
        analysis = analyze_conversation_for_problems(ai_context)
        
        if analysis:
            # Send to Teams with detailed analysis
            teams_sent = send_enhanced_teams_notification(ai_context, analysis)
            
            if teams_sent:
                send_to_chatwoot(conv_id, f"""
‚úÖ –ê–º–∂–∏–ª—Ç—Ç–∞–π! –¢–∞–Ω—ã –∞—Å—É—É–¥–ª—ã–≥ –¥—ç–º–∂–ª—ç–≥–∏–π–Ω –±–∞–≥—Ç –∏–ª–≥—ç—ç–ª—ç—ç.

üìß **Email:** {user_email}
‚è∞ **–•“Ø–ª—ç—ç—Ö —Ö—É–≥–∞—Ü–∞–∞:** 1-2 –∞–∂–ª—ã–Ω ”©–¥”©—Ä

–î—ç–º–∂–ª—ç–≥–∏–π–Ω –±–∞–≥ —Ç–∞–Ω–∞–π email —Ö–∞—è–≥ —Ä—É—É —Ö–æ–ª–±–æ–≥–¥–æ—Ö –±–æ–ª–Ω–æ.

”®”©—Ä –∞—Å—É—É–ª—Ç –±–∞–π–≤–∞–ª —á”©–ª”©”©—Ç—ç–π –∞—Å—É—É–≥–∞–∞—Ä–∞–π! üòä
                """)
            else:
                send_to_chatwoot(conv_id, "‚ùå Teams —Ä—É—É –∏–ª–≥—ç—ç—Ö—ç–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞. –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É.")
        else:
            # Fallback - send basic Teams notification
            context_info = ai_context.get_full_context()
            basic_teams_message = f"""
üö® **–î–≠–ú–ñ–õ–≠–ì –•“Æ–°–≠–õ–¢**

üë§ **–•—ç—Ä—ç–≥–ª—ç–≥—á:** {contact_name}
üìß **–ò–º—ç–π–ª:** {user_email}
üÜî **Conversation ID:** {conv_id}

üí¨ **–•–∞—Ä–∏–ª—Ü–ª–∞–≥–∞:**
{context_info['full_conversation'][-500:]}

üïí **–û–≥–Ω–æ–æ:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
            """
            
            teams_sent = send_to_teams(
                message=basic_teams_message,
                title=f"üìß {contact_name} - –î—ç–º–∂–ª—ç–≥ —Ö“Ø—Å—ç–ª—Ç",
                color="FF6B35",
                conv_id=conv_id
            )
            
            if teams_sent:
                send_to_chatwoot(conv_id, f"‚úÖ –¢–∞–Ω—ã –∞—Å—É—É–¥–ª—ã–≥ –¥—ç–º–∂–ª—ç–≥–∏–π–Ω –±–∞–≥—Ç –∏–ª–≥—ç—ç–ª—ç—ç ({user_email}). –¢—É–Ω —É–¥–∞—Ö–≥“Ø–π —Ö–æ–ª–±–æ–≥–¥–æ—Ö –±–æ–ª–Ω–æ.")
        
        # Clear waiting state
        conversation_memory[conv_id] = [msg for msg in conversation_memory[conv_id] 
                                     if "waiting_for_email" not in msg.get("content", "")]
        
    else:
        send_to_chatwoot(conv_id, """
‚ùå –ë—É—Ä—É—É email —Ö—ç–ª–±—ç—Ä –±–∞–π–Ω–∞.

üìß **–ó”©–≤ —Ö—ç–ª–±—ç—Ä:** example@gmail.com
üí° **–¶—É—Ü–ª–∞—Ö:** "—Ü—É—Ü–ª–∞—Ö" –≥—ç–∂ –±–∏—á–Ω—ç “Ø“Ø
        """)

# Legacy function for backward compatibility  
def get_ai_response(user_message: str, conversation_id: int, context_data: list = None):
    """Legacy wrapper for backward compatibility"""
    ai_context = AIContext(conversation_id, user_message)
    return get_enhanced_ai_response(ai_context)


# ‚Äî‚Äî Additional API Endpoints ‚Äî‚Äî #
@app.route("/api/crawl-status", methods=["GET"])
def get_crawl_status():
    """Get current crawl status"""
    return jsonify({
        "crawl_status": crawl_status,
        "crawled_pages": len(crawled_data),
        "config": {
            "root_url": ROOT_URL,
            "auto_crawl_enabled": AUTO_CRAWL_ON_START,
            "max_pages": MAX_CRAWL_PAGES
        }
    })

@app.route("/api/force-crawl", methods=["POST"])
def force_crawl():
    """Force start a new crawl"""
    global crawled_data, crawl_status
    
    # Check if already running
    if crawl_status["status"] == "running":
        return jsonify({"error": "Crawl is already running"}), 409
    
    try:
        crawl_status = {"status": "running", "message": "Force crawl started via API"}
        crawled_data = crawl_and_scrape(ROOT_URL)
        
        if crawled_data:
            crawl_status = {
                "status": "completed",
                "message": f"Force crawl completed via API",
                "pages_count": len(crawled_data),
                "timestamp": datetime.now().isoformat()
            }
            return jsonify({
                "status": "success",
                "pages_crawled": len(crawled_data),
                "crawl_status": crawl_status
            })
        else:
            crawl_status = {"status": "failed", "message": "Force crawl failed - no pages found"}
            return jsonify({"error": "No pages were crawled"}), 500
            
    except Exception as e:
        crawl_status = {"status": "error", "message": f"Force crawl error: {str(e)}"}
        return jsonify({"error": f"Crawl failed: {e}"}), 500

@app.route("/api/search", methods=["POST"])
def api_search():
    """Search through crawled data via API"""
    data = request.get_json(force=True)
    query = data.get("query", "").strip()
    max_results = data.get("max_results", 5)
    
    if not query:
        return jsonify({"error": "Missing 'query' in request body"}), 400
    
    if crawl_status["status"] == "running":
        return jsonify({"error": "Crawl is currently running, please wait"}), 409
    
    if not crawled_data:
        return jsonify({"error": "No crawled data available. Run crawl first."}), 404
    
    results = search_in_crawled_data(query, max_results)
    return jsonify({
        "query": query,
        "results_count": len(results),
        "results": results,
        "crawl_status": crawl_status
    })

@app.route("/api/conversation/<int:conv_id>/memory", methods=["GET"])
def get_conversation_memory(conv_id):
    """Get conversation memory for debugging"""
    memory = conversation_memory.get(conv_id, [])
    return jsonify({"conversation_id": conv_id, "memory": memory})

@app.route("/api/conversation/<int:conv_id>/clear", methods=["POST"])
def clear_conversation_memory(conv_id):
    """Clear conversation memory"""
    if conv_id in conversation_memory:
        del conversation_memory[conv_id]
    return jsonify({"status": "cleared", "conversation_id": conv_id})

@app.route("/api/crawled-data", methods=["GET"])
def get_crawled_data():
    """Get current crawled data"""
    page_limit = request.args.get('limit', 10, type=int)
    return jsonify({
        "total_pages": len(crawled_data), 
        "crawl_status": crawl_status,
        "data": crawled_data[:page_limit]
    })

@app.route("/health", methods=["GET"])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "crawl_status": crawl_status,
        "crawled_pages": len(crawled_data),
        "active_conversations": len(conversation_memory),
        "config": {
            "root_url": ROOT_URL,
            "auto_crawl_enabled": AUTO_CRAWL_ON_START,
            "openai_configured": client is not None,
            "chatwoot_configured": bool(CHATWOOT_API_KEY and ACCOUNT_ID)
        }
    })


# 1. “Æ–π–ª—á–∏–ª–≥—ç—ç–Ω–∏–π –Ω—ç—Ä—Å–∏–π–Ω –∂–∞–≥—Å–∞–∞–ª—Ç - SERVICE_PRICES-—Ç—ç–π —Ç–æ—Ö–∏—Ä–æ—Ö
SERVICE_KEYWORDS = [
    "Nginx", "apache2", "httpd", "php", "wordpress", "phpMyAdmin", "—Å–µ—Ä–≤–µ—Ä —Å—É—É–ª–≥–∞—Ö", "—Å–µ—Ä–≤–∏—Å —Å—É—É–ª–≥–∞—Ö",
    "Database", "SQL", "NoSQL", "”©–≥”©–≥–¥–ª–∏–π–Ω —Å–∞–Ω",
    "VPN —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö", "VPN", "–≤–∏—Ä—Ç—É–∞–ª –Ω—ç—Ç–≤–æ—Ä–∫",
    "–•—ç—Ä—ç–≥–ª—ç–≥—á —Ö–æ–æ—Ä–æ–Ω–¥ —Å–µ—Ä–≤–µ—Ä –∑”©”©—Ö", "—Å–µ—Ä–≤–µ—Ä –∑”©”©—Ö", "—Ñ–∞–π–ª –∑”©”©—Ö", "migration",
    "Windows —Å–µ—Ä–≤–µ—Ä", "Windows –ª–∏—Ü–µ–Ω–∑", "–ª–∏—Ü–µ–Ω–∑ —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö",
    "—Å–µ—Ä–≤–µ—Ä–∏–π–≥ “Ø“Ø—Å–≥—ç–∂ ”©–≥”©—Ö", "–ø–æ—Ä—Ç —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö", "firewall", "network",
    "DNS record", "DNS —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö", "–¥–æ–º—ç–π–Ω",
    "–º—ç–π–ª —Å–µ—Ä–≤–µ—Ä", "email server", "smtp", "pop3", "imap",
    "–Ω—É—É—Ü “Ø–≥ —Å—ç—Ä–≥—ç—ç—Ö", "password reset", "—Ö–∞–Ω–¥–∞–ª—Ç —Å—ç—Ä–≥—ç—ç—Ö",
    "SSL —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö", "SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç", "HTTPS", "—à–∏—Ñ—Ä–ª—ç–ª—Ç",
    "–Ω“Ø“Ø–¥—ç–ª —Å—ç—Ä–≥—ç—ç—Ö", "backup restore", "—Å—ç—Ä–≥—ç—ç—Ö",
    "—Ñ–∞–π–ª —Ö—É—É–ª–∞—Ö", "local —Ä—É—É —Ö—É—É–ª–∞—Ö", "download", "file transfer",
    "—Å“Ø–ª–∂—ç—ç–Ω–∏–π –∞–ª–¥–∞–∞", "network error", "connectivity issue",
    "–∞—é—É–ª–≥“Ø–π –±–∞–π–¥–∞–ª", "security", "–∞—É–¥–∏—Ç", "log —Ü—É–≥–ª—É—É–ª–∞—Ö",
    "—Ñ–∏–∑–∏–∫ —Å–µ—Ä–≤–µ—Ä", "VPS", "–≤–∏—Ä—Ç—É–∞–ª –º–∞—à–∏–Ω", "–∫–ª–∞—É–¥ —Å–µ—Ä–≤–µ—Ä",
    "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π–Ω –∑”©–≤–ª”©—Ö", "consulting", "–∑”©–≤–ª”©–≥”©”©",
    "—Å–µ—Ä–≤–µ—Ä–∏–π–Ω –∞–ª–¥–∞–∞", "system error", "debugging", "troubleshooting"
]

def contains_service_or_support(text):
    """Enhanced service and support detection"""
    text_lower = text.lower()
    found_service = any(service.lower() in text_lower for service in SERVICE_KEYWORDS)
    return found_service

def get_services_in_text(text):
    """Enhanced service detection in text"""
    found = []
    text_lower = text.lower()
    
    for key, info in SERVICE_PRICES.items():
        # Check if service name or related keywords are mentioned
        service_keywords = key.lower().split()
        if any(keyword in text_lower for keyword in service_keywords):
            found.append((key, info))
        
        # Also check SERVICE_KEYWORDS for broader matching
        for keyword in SERVICE_KEYWORDS:
            if keyword.lower() in text_lower and keyword.lower() in key.lower():
                if (key, info) not in found:
                    found.append((key, info))
    
    return found


# ‚Äî‚Äî New Service Prices ‚Äî‚Äî #
SERVICE_PRICES = {
    "Nginx, apache2, httpd, php, wordpress, phpMyAdmin –∑—ç—Ä—ç–≥ —Å–µ—Ä–≤–∏—Å —Å—É—É–ª–≥–∞—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 55,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 88,000‚ÇÆ",
        "desc": "Nginx, apache2, httpd, php, wordpress, phpMyAdmin –∑—ç—Ä—ç–≥ —Å–µ—Ä–≤–∏—Å —Å—É—É–ª–≥–∞—Ö",
        "server_inside": True, "server_outside": False, "duration": "10min per service only for installation"
    },
    "Database, SQL, NoSQL —Å–µ—Ä–≤–∏—Å —Å—É—É–ª–≥–∞—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 55,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 88,000‚ÇÆ",
        "desc": "Database, SQL, NoSQL —Å–µ—Ä–≤–∏—Å —Å—É—É–ª–≥–∞—Ö",
        "server_inside": True, "server_outside": False, "duration": "10min per service only for installation"
    },
    "VPN —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 88,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 110,000‚ÇÆ",
        "desc": "VPN —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö",
        "server_inside": True, "server_outside": False, "duration": "60-120"
    },
    "–•—ç—Ä—ç–≥–ª—ç–≥—á —Ö–æ–æ—Ä–æ–Ω–¥ —Å–µ—Ä–≤–µ—Ä –∑”©”©—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 55,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 88,000‚ÇÆ",
        "desc": "–•—ç—Ä—ç–≥–ª—ç–≥—á —Ö–æ–æ—Ä–æ–Ω–¥ —Å“Ø–ª–∂—ç—ç –∑”©”©—Ö",
        "server_inside": True, "server_outside": False, "duration": "–î–∏—Å–∫–∏–π–Ω —Ö—ç–º–∂—ç—ç–Ω—ç—ç—Å —Ö–∞–º–∞–∞—Ä–Ω–∞. 20min for 15GB"
    },
    "Windows —Å–µ—Ä–≤–µ—Ä –¥—ç—ç—Ä –ª–∏—Ü–µ–Ω–∑ —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 55,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 88,000‚ÇÆ",
        "desc": "Windows —Å–µ—Ä–≤–µ—Ä –¥—ç—ç—Ä —à–∏–Ω—ç—ç—Ä —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö",
        "server_inside": True, "server_outside": False, "duration": "30-60"
    },
    "–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω —Å–µ—Ä–≤–µ—Ä–∏–π–≥ “Ø“Ø—Å–≥—ç–∂ ”©–≥”©—Ö, –ø–æ—Ä—Ç —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 55,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 88,000‚ÇÆ",
        "desc": "–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω —Å–µ—Ä–≤–µ—Ä–∏–π–Ω “Ø“Ø—Ä—ç–≥, –ø–æ—Ä—Ç —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö",
        "server_inside": True, "server_outside": False, "duration": "20"
    },
    "DNS record —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 33,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 55,000‚ÇÆ",
        "desc": "DNS record —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö",
        "server_inside": True, "server_outside": False, "duration": "30-60"
    },
    "–ú—ç–π–ª —Å–µ—Ä–≤–µ—Ä –¥—ç—ç—Ä —Ç—É—Å–ª–∞–ª—Ü–∞–∞ “Ø–∑“Ø“Ø–ª—ç—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 55,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 88,000‚ÇÆ",
        "desc": "–°–µ—Ä–≤–µ—Ä—ç—ç—Å ”©–≥”©–≥–¥”©–ª —Å—ç—Ä–≥—ç—ç—Ö",
        "server_inside": True, "server_outside": False, "duration": "30 +"
    },
    "–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –Ω—É—É—Ü “Ø–≥ —Å—ç—Ä–≥—ç—ç—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 55,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 88,000‚ÇÆ",
        "desc": "–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –Ω“Ø“Ø–≥–¥—ç–ª —Å—ç—Ä–≥—ç—ç—Ö",
        "server_inside": True, "server_outside": False, "duration": "30 +"
    },
    "SSL —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 55,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 88,000‚ÇÆ",
        "desc": "SSL —Ç–æ—Ö–∏—Ä—É—É–ª–∞—Ö",
        "server_inside": True, "server_outside": False, "duration": "30-60"
    },
    "–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –Ω“Ø“Ø–¥—ç–ª —Å—ç—Ä–≥—ç—ç—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 55,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 88,000‚ÇÆ",
        "desc": "–•—ç—Ä—ç–≥–ª—ç–≥—á–∏–π–Ω –Ω“Ø“Ø–¥—ç–ª —Å—ç—Ä–≥—ç—ç—Ö",
        "server_inside": True, "server_outside": False, "duration": "30 +"
    },
    "–ö–ª–∞—É–¥ —Å–µ—Ä–≤–µ—Ä—ç—ç—Å local —Ä—É—É —Ñ–∞–π–ª —Ö—É—É–ª–∞—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 77,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 110,000‚ÇÆ",
        "desc": "–ö–ª–∞—É–¥ —Å–µ—Ä–≤–µ—Ä—ç—ç—Å local —Ä—É—É —Ñ–∞–π–ª —Ö—É—É–ª–∞—Ö",
        "server_inside": True, "server_outside": False, "duration": "–§–∞–π–ª—ã–Ω —Ö—ç–º–∂—ç—ç, –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∏–π–Ω —Ö—É—Ä–¥–Ω–∞–∞—Å —Ö–∞–º–∞–∞—Ä–Ω–∞. –£—Ä—å–¥—á–∏–ª–∞–Ω —Ö—É–≥–∞—Ü–∞–∞ —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö –±–æ–ª–æ–º–∂–≥“Ø–π."
    },
    "–°“Ø–ª–∂—ç—ç–Ω–∏–π –±—É—Ä—É—É —Ç–æ—Ö–∏—Ä–≥–æ–æ–Ω–æ–æ—Å “Ø“Ø—Å—Å—ç–Ω –∞–ª–¥–∞–∞ –∑–∞—Å–≤–∞—Ä–ª–∞—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 55,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 88,000‚ÇÆ",
        "desc": "–°“Ø–ª–∂—ç—ç–Ω–∏–π –±—É—Ä—É—É —Ç–æ—Ö–∏—Ä–≥–æ–æ–Ω–æ–æ—Å “Ø“Ø—Å—Å—ç–Ω –∞–ª–¥–∞–∞ –∑–∞—Å–≤–∞—Ä–ª–∞—Ö",
        "server_inside": True, "server_outside": False, "duration": "–ê–ª–¥–∞–∞–Ω—ã —Ö—ç–º–∂—ç—ç–Ω—ç—ç—Å —Ö–∞–º–∞–∞—Ä–Ω–∞. –£—Ä—å–¥—á–∏–ª–∞–Ω —Ö—É–≥–∞—Ü–∞–∞ —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö –±–æ–ª–æ–º–∂–≥“Ø–π."
    },
    "–§–∏–∑–∏–∫ —Å–µ—Ä–≤–µ—Ä, VPS –±–æ–ª–æ–Ω –±—É—Å–∞–¥ –∫–ª–∞—É–¥ –≤–∏—Ä—Ç—É–∞–ª –º–∞—à–∏–Ω/—Å–µ—Ä–≤–µ—Ä “Ø“Ø—Å–≥—ç—Ö": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 110,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 132,000‚ÇÆ",
        "desc": "–§–∏–∑–∏–∫ —Å–µ—Ä–≤–µ—Ä, VPS –±–æ–ª–æ–Ω –±—É—Å–∞–¥ –∫–ª–∞—É–¥ –≤–∏—Ä—Ç—É–∞–ª –º–∞—à–∏–Ω/—Å–µ—Ä–≤–µ—Ä “Ø“Ø—Å–≥—ç—Ö",
        "server_inside": False, "server_outside": True, "duration": "—Ö–∞–º–∞–∞—Ä–Ω–∞"
    },
    "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–π–Ω –±—É—Å–∞–¥ —Ç”©—Ä–ª–∏–π–Ω –∑”©–≤–ª”©—Ö “Ø–π–ª—á–∏–ª–≥—ç—ç": {
        "price": "–ê–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä 110,000‚ÇÆ, –ê–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä 132,000‚ÇÆ",
        "desc": "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–π–Ω –±—É—Å–∞–¥ —Ç”©—Ä–ª–∏–π–Ω –∑”©–≤–ª”©—Ö “Ø–π–ª—á–∏–ª–≥—ç—ç",
        "server_inside": True, "server_outside": True, "duration": "60"
    },
    "–ù–∏–π–ª“Ø“Ø–ª—ç–≥—á—ç—ç—Å —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π —Å–µ—Ä–≤–µ—Ä–∏–π–Ω –¥–æ—Ç–æ–æ–¥ –∞–ª–¥–∞–∞ –∏–ª—Ä“Ø“Ø–ª—ç—Ö, –∑–∞—Å–≤–∞—Ä–ª–∞—Ö": {
        "price": "110,000‚ÇÆ (–∞–∂–ª—ã–Ω —Ü–∞–≥–∞–∞—Ä), 132,000‚ÇÆ (–∞–∂–ª—ã–Ω –±—É—Å —Ü–∞–≥–∞–∞—Ä)",
        "desc": "–ù–∏–π–ª“Ø“Ø–ª—ç–≥—á—ç—ç—Å —à–∞–∞—Ä–¥–ª–∞–≥–∞—Ç–∞–π —Å–µ—Ä–≤–µ—Ä–∏–π–Ω –¥–æ—Ç–æ–æ–¥ –∞–ª–¥–∞–∞ –∏–ª—Ä“Ø“Ø–ª—ç—Ö, –∑–∞—Å–≤–∞—Ä–ª–∞—Ö",
        "server_inside": True, "server_outside": False, "duration": "–ê–ª–¥–∞–∞–Ω—ã —Ö—ç–º–∂—ç—ç–Ω—ç—ç—Å —Ö–∞–º–∞–∞—Ä–Ω–∞, —É—Ä—å–¥—á–∏–ª–∞–Ω —Ö—É–≥–∞—Ü–∞–∞ —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö –±–æ–ª–æ–º–∂–≥“Ø–π."
    }
}


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)
